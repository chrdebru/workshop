<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

	<title>KGC Workshop</title>

	<!-- Google font -->
	<link href="https://fonts.googleapis.com/css?family=Poppins:400,700,900" rel="stylesheet">

	<!-- Bootstrap -->
	<link type="text/css" rel="stylesheet" href="css/bootstrap.min.css" />

	<!-- Owl Carousel -->
	<link type="text/css" rel="stylesheet" href="css/owl.carousel.css" />
	<link type="text/css" rel="stylesheet" href="css/owl.theme.default.css" />

	<!-- Font Awesome Icon -->
	<link rel="stylesheet" href="css/font-awesome.min.css">

	<!-- Custom stlylesheet -->
	<link type="text/css" rel="stylesheet" href="css/style.css" />

	<!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
	<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
	<!--[if lt IE 9]>
	<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
	<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
	<![endif]-->
</head>
<body>

<!-- Header -->
<header id="header" class="transparent-navbar">
	<!-- container -->
	<div class="container">
		<!-- navbar header -->
		<div class="navbar-header">
			<!-- Logo -->
			<!--<div class="navbar-brand">
                <a class="logo" href="index.html">
                    <img class="logo-img" src="./img/rdf.png" alt="logo">
                    <img class="logo-alt-img" src="./img/rdf.png" alt="logo">
                </a>
            </div>-->
			<!-- /Logo -->

			<!-- Mobile toggle -->
			<button class="navbar-toggle">
				<i class="fa fa-bars"></i>
			</button>
			<!-- /Mobile toggle -->
		</div>
		<!-- /navbar header -->

		<!-- Navigation -->
		<nav id="nav">
			<ul class="main-nav nav navbar-nav navbar-right" >
				<li><a href="./index.html#call" style="color:rgb(24, 29, 33); !important">Call</a></li>
				<li><a href="./index.html#program" style="color:rgb(24, 29, 33); !important">Program</a></li>
				<li><a href="./index.html#important-dates" style="color:rgb(24, 29, 33); !important">Important dates</a></li>
				<li><a href="./index.html#organization" style="color:rgb(24, 29, 33); !important">Organization</a></li>
				<li><a href="./index.html#pc" style="color:rgb(24, 29, 33); !important">Program Committee</a></li>
			</ul>
		</nav>
		<!-- /Navigation -->
	</div>
	<!-- /container -->
</header>
<!-- /Header -->

<!-- About -->
<div id="call" class="section">
	<!-- container -->
	<div class="container">
		<!-- row -->
		<div class="row">
			<!-- section title -->
			<div class="section-title">
                <h2 class="title"><span>KGCW2023</span> <span style="color: #dd0a37;"> Challenge </span> </h2>
			</div>
			<!-- /section title -->

			<div class="col-md-10 col-md-offset-1 text-justify">
				<div class="about-content" style="font-size: 14pt">
                    <h3 class="title"><span style="color: #dd0a37;">Task Description</span></h3>

				</div>
                <div class="about-content" style="font-size: 14pt">
                    <p>
											The task is to reduce and report the execution time and computing resources (CPU and memory usage) for the parameters listed in this challenge, compared to the state-of-the-art of the existing tools and the baseline results provided by this challenge. This challenge is not limited to execution times to create the fastest pipeline, but also computing resources to achieve the most efficient pipeline.
										</p>
										<p>
											We provide a tool which can execute such pipelines end-to-end. This tool also collects and aggregates the metrics such as execution time, CPU and memory usage, necessary for this challenge as CSV files. Moreover, the information about the hardware used during the execution of the pipeline is available as well to allow fairly comparing different pipelines. Your pipeline should consist of Docker images which can be executed on Linux to run the tool. The tool is already tested with existing systems, relational databases e.g. MySQL and PostgreSQL, and triplestores e.g. Apache Jena Fuseki and OpenLink Virtuoso which can be combined in any configuration. However, it is not a requirement to use this tool for participating in this challenge.

                    </p>
                </div>

			</div>

			<div class="col-md-10 col-md-offset-1 text-justify">
				<div class="about-content" style="font-size: 14pt">
                    <h3 class="title"><span style="color: #dd0a37;">Part 1: Knowledge Graph Construction Parameters</span></h3>

				</div>
                <div class="about-content" style="font-size: 14pt">
                    <p>
											These parameters are evaluated using synthetic generated data to have more insights of their influence on the pipeline.
										</p>
										<p>
											<b>Data</b>
											<ul>
												<li>Number of data records: scaling the data size vertically by the number of records with a fixed number of data properties (10K, 100K, 500K, 1M, 5M records).</li>
												<li>Number of data properties: scaling the data size horizontally by the number of data properties with a fixed number of data records (5, 10, 15, 20, 25, 30 columns).</li>
												<li>Number of duplicate values: scaling the number of duplicate values in the dataset.</li>
												<li>Number of empty values: scaling the number of empty values in the dataset.</li>
											</ul>
                    </p>
										<p>
											<b>Mappings</b>
											<ul>
												<li>Number of subjects: scaling the number of subjects with a fixed number of predicates and objects.</li>
												<li>Number of predicates and objects: scaling the number of predicates and objects with a fixed number of subjects.</li>
												<li>Number of and type of joins: scaling the number of joins and type of joins (1-1, N-1, 1-N, N-M).</li>
											</ul>
                    </p>
										<p>
											<b>Output</b>
											<ul>
												<li>Number of files: scaling the number of output files.</li>
												<li>Serialization format: variating the serialization format.</li>
											</ul>
                    </p>
                </div>

			</div>


			<div class="col-md-10 col-md-offset-1 text-justify">
				<div class="about-content" style="font-size: 14pt">
                    <h3 class="title"><span style="color: #dd0a37;">Part 2: GTFS-Madrid-Bench</span></h3>

				</div>
                <div class="about-content" style="font-size: 14pt">
                    <p>
											The GTFS-Madrid-Bench provides insights in the pipeline with real data from the public transport domain in Madrid.
										</p>
										<p>
											<b>Scaling</b>
											<ul>
												<li>GTFS-1 SQL</li>
												<li>GTFS-10 SQL</li>
												<li>GTFS-100 SQL</li>
												<li>GTFS-1000 SQL</li>
											</ul>
                    </p>
										<p>
											<b>Heterogeneity</b>
											<ul>
												<li>GTFS-100 with XML + JSON</li>
												<li>GTFS-100 with CSV + XML</li>
												<li>GTFS-100 with CSV + JSON</li>
												<li>GTFS-100 with SQL + XML + JSON + CSV</li>
											</ul>
                    </p>
                </div>

			</div>


			<div class="col-md-10 col-md-offset-1 text-justify">
				<div class="about-content" style="font-size: 14pt">
                    <h3 class="title"><span style="color: #dd0a37;">Example pipeline</span></h3>

				</div>
                <div class="about-content" style="font-size: 14pt">
                    <p>
											The ground truth dataset and baseline results are generated in different steps for each parameter:
										</p>
										<p>
											<ol>
												<li>The provided CSV files and SQL schema are loaded into a PostgreSQL relational database.</li>
												<li>RMLMapper executed the provided mappings by accessing the PostgreSQL relational database to construct a knowledge graph in N-Triples as RDF format.</li>
												<li>The constructed knowledge graph is loaded into a Virtuoso triplestore, tuned according to the Virtuoso documentation.</li>
												<li>The provided SPARQL queries are executed on the SPARQL endpoint exposed by Virtuos.</li>
											</ol>
                    </p>
										<p>
											The pipeline is executed 5 times from which the median execution time of each step is calculated and reported. Each step with the median execution time is then reported in the baseline results with all its measured metrics. Query timeout is set to 1 hour and knowledge graph construction timeout to 6 hours. The execution is performed with the following tool <TOOL LINK>, you can adapt the execution plans for this example pipeline to your own needs.
                    </p>
										<p>
											Each parameter has its own directory in the ground truth dataset with the following files:
											<ul>
												<li>Input dataset as CSV.</li>
												<li>Mapping file as RML.</li>
												<li>Queries as SPARQL.</li>
												<li>Measured metrics in <tt>aggregated.csv</tt>.</li>
												<li>Hardware setup in <tt>case-info.txt</tt> to allow a fair comparison in terms of CPU cores, RAM memory, and storage.</li>
												<li>Execution plan for the pipeline in <tt>metadata.json</tt>.</li>
											</ul>
                    </p>
                </div>

			</div>


			<div class="col-md-10 col-md-offset-1 text-justify">
				<div class="about-content" style="font-size: 14pt">
                    <h3 class="title"><span style="color: #dd0a37;">Datasets</span></h3>

				</div>
					<div class="about-content" style="font-size: 14pt">
	                    <h4 class="title"><span style="color: #dd0a37;">Knowledge Graph Construction Parameters</span></h4>

					</div>
                <div class="about-content" style="font-size: 14pt">
                    <p>
											The dataset consists of:
										</p>
										<p>
											<ol>
												<li>Input dataset as CSV for each parameter.</li>
												<li>Mapping file as RML for each parameter.</li>
												<li>SPARQL queries to retrieve the results for each parameter.</li>
												<li>Baseline results for each parameter with the example pipeline.</li>
												<li>Ground truth dataset for each parameter generated with the example pipeline.</li>
											</ol>
                    </p>
										<p>
											<b>Format</b>: All input datasets are provided as CSV, depending on the parameter that is being evaluated, the number of rows and columns may differ. The first row is always the header of the CSV.
                    </p>
										<p>
											<b>Link</b>: <zenodo link>
                    </p>

                </div>
									<div class="about-content" style="font-size: 14pt">
					                    <h4 class="title"><span style="color: #dd0a37;">GTFS-Madrid-Bench</span></h4>

									</div>
				                <div class="about-content" style="font-size: 14pt">
				                    <p>
															The dataset consists of:
														</p>
														<p>
															<ol>
																<li>Input dataset as CSV for the scaling and a combination of XML, CSV, and JSON is provided for the heterogeneity.</li>
																<li>Mapping file as RML for both scaling and heterogeneity.</li>
																<li>SPARQL queries to retrieve the results.</li>
																<li>Baseline results with the example pipeline.</li>
																<li>Ground truth dataset generated with the example pipeline.</li>
															</ol>
				                    </p>
														<p>
															<b>Format</b>: CSV datasets always have a header as their first row. JSON and XML datasets have their own schema.
				                    </p>
														<p>
															<b>Link</b>: <zenodo link>
				                    </p>

				                </div>
			</div>


			<div class="col-md-10 col-md-offset-1 text-justify">
				<div class="about-content" style="font-size: 14pt">
                    <h3 class="title"><span style="color: #dd0a37;">Evaluation Criteria</span></h3>

				</div>
                <div class="about-content" style="font-size: 14pt">
                    <p>
											Submissions must evaluate the following metrics:
											<ul>
												<li><b>Execution time</b> of all the steps in the pipeline. The execution time of a step is the difference between the begin and end time of a step.</li>
												<li><b>CPU time</b> as the time spent in the CPU for all steps of the pipeline. The CPU time of a step is the difference between the begin and end CPU time of a step.</li>
												<li>Minimal and maximal <b>memory</b> consumption for each step of the pipeline. The minimal and maximal memory consumption of a step is the minimum and maximum calculated of the memory consumption during the execution of a step.</li>
											</ul>
                    </p>
                </div>
			</div>


		</div>

	</div>

	<!-- /container -->
</div>
<!-- /About -->

<!-- Footer -->
<footer id="footer">
	<!-- container -->
	<div class="col-md-8 col-sm-6 col-xs-8 col-md-offset-2 text-center" >
		Copyright &copy;<script>document.write(new Date().getFullYear());</script> All rights reserved | This template is made with <i class="fa fa-heart-o" aria-hidden="true"></i> by <a href="https://colorlib.com" target="_blank">Colorlib</a>
						<!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. --></span>
	</div>
			<!-- /copyright -->

	<!-- /container -->
</footer>
<!-- /Footer -->

<!-- jQuery Plugins -->
<script src="js/jquery.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/jquery.waypoints.min.js"></script>
<script src="js/owl.carousel.min.js"></script>
<script src="js/jquery.stellar.min.js"></script>
<script src="js/jquery.countTo.js"></script>
<script src="js/main.js"></script>

</body>

</html>
